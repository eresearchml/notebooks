{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as DT\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy as sp\n",
    "import datetime\n",
    "from IPython.core.debugger import Tracer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics.classification import log_loss\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import operator\n",
    "import itertools\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats.stats import pearsonr\n",
    "import scipy\n",
    "\n",
    "import utils as ut\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in new data set and get an idea of dimensions\n",
    "## 1) load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coltodatetime(df, col):\n",
    "    df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n",
    "def splitcol(df, col, char):\n",
    "    df[col] =df[col].fillna('')\n",
    "    r = df[col].apply(lambda x: pd.Series(x.split(char)))\n",
    "    for i in range(0, r.shape[1]):\n",
    "        df[col + str(i)] = r[i]\n",
    "    #del df[col]\n",
    "def combinedatentime(df, datecol, timecol, newcol):\n",
    "    df[newcol] = df.apply(lambda row: datetime.datetime.combine(row[datecol].date(), row[timecol].time()), axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape\n",
      "(100000, 33)\n",
      "Columns\n",
      "IncidentNumber                                     int64\n",
      "DateOfCall                                datetime64[ns]\n",
      "TimeOfCall                                datetime64[ns]\n",
      "IncidentGroup                                     object\n",
      "StopCodeDescription                               object\n",
      "SpecialServiceType                                object\n",
      "PropertyCategory                                  object\n",
      "PropertyType                                      object\n",
      "AddressQualifier                                  object\n",
      "Postcode_full                                     object\n",
      "Postcode_district                                 object\n",
      "IncGeo_BoroughCode                                object\n",
      "IncGeo_BoroughName                                object\n",
      "IncGeo_WardCode                                   object\n",
      "IncGeo_WardName                                   object\n",
      "Easting_m                                        float64\n",
      "Northing_m                                       float64\n",
      "Easting_rounded                                    int64\n",
      "Northing_rounded                                   int64\n",
      "FRS                                               object\n",
      "IncidentStationGround                             object\n",
      "FirstPumpArriving_AttendanceTime                 float64\n",
      "FirstPumpArriving_DeployedFromStation             object\n",
      "SecondPumpArriving_AttendanceTime                float64\n",
      "SecondPumpArriving_DeployedFromStation            object\n",
      "NumStationsWithPumpsAttending                    float64\n",
      "NumPumpsAttending                                float64\n",
      "Postcode_full0                                    object\n",
      "Postcode_full1                                    object\n",
      "DatetimeOfCall                            datetime64[ns]\n",
      "hour                                               int64\n",
      "month                                              int64\n",
      "weekday                                            int64\n",
      "dtype: object\n",
      "Samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentNumber</th>\n",
       "      <th>DateOfCall</th>\n",
       "      <th>TimeOfCall</th>\n",
       "      <th>IncidentGroup</th>\n",
       "      <th>StopCodeDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235138081</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-01-24 00:00:37</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>Special Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1091</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-01-24 00:00:46</td>\n",
       "      <td>Special Service</td>\n",
       "      <td>Special Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2091</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-01-24 00:03:00</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Secondary Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3091</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-01-24 00:04:27</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Secondary Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5091</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>2017-01-24 00:05:39</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Secondary Fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IncidentNumber DateOfCall          TimeOfCall    IncidentGroup  \\\n",
       "0       235138081 2009-01-01 2017-01-24 00:00:37  Special Service   \n",
       "1            1091 2009-01-01 2017-01-24 00:00:46  Special Service   \n",
       "2            2091 2009-01-01 2017-01-24 00:03:00             Fire   \n",
       "3            3091 2009-01-01 2017-01-24 00:04:27             Fire   \n",
       "4            5091 2009-01-01 2017-01-24 00:05:39             Fire   \n",
       "\n",
       "  StopCodeDescription  \n",
       "0     Special Service  \n",
       "1     Special Service  \n",
       "2      Secondary Fire  \n",
       "3      Secondary Fire  \n",
       "4      Secondary Fire  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpecialServiceType</th>\n",
       "      <th>PropertyCategory</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>AddressQualifier</th>\n",
       "      <th>Postcode_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RTC</td>\n",
       "      <td>Road Vehicle</td>\n",
       "      <td>Car</td>\n",
       "      <td>In street close to</td>\n",
       "      <td>SW11 4LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assist other agencies</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Lake/pond/reservoir</td>\n",
       "      <td>Open land/water - nearest address to access</td>\n",
       "      <td>SE1 7SG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Road surface/pavement</td>\n",
       "      <td>In street outside</td>\n",
       "      <td>N9 9EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Domestic garden (vegetation not equipment)</td>\n",
       "      <td>On land associated with building</td>\n",
       "      <td>UB10 0DG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Cycle path/public footpath/bridleway</td>\n",
       "      <td>In street outside</td>\n",
       "      <td>N7 8HG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SpecialServiceType PropertyCategory  \\\n",
       "0                    RTC     Road Vehicle   \n",
       "1  Assist other agencies          Outdoor   \n",
       "2                    NaN          Outdoor   \n",
       "3                    NaN          Outdoor   \n",
       "4                    NaN          Outdoor   \n",
       "\n",
       "                                  PropertyType  \\\n",
       "0                                         Car    \n",
       "1                         Lake/pond/reservoir    \n",
       "2                       Road surface/pavement    \n",
       "3  Domestic garden (vegetation not equipment)    \n",
       "4        Cycle path/public footpath/bridleway    \n",
       "\n",
       "                              AddressQualifier Postcode_full  \n",
       "0                           In street close to      SW11 4LB  \n",
       "1  Open land/water - nearest address to access       SE1 7SG  \n",
       "2                            In street outside        N9 9EL  \n",
       "3             On land associated with building      UB10 0DG  \n",
       "4                            In street outside        N7 8HG  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode_district</th>\n",
       "      <th>IncGeo_BoroughCode</th>\n",
       "      <th>IncGeo_BoroughName</th>\n",
       "      <th>IncGeo_WardCode</th>\n",
       "      <th>IncGeo_WardName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SW11</td>\n",
       "      <td>E09000032</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>E05000620</td>\n",
       "      <td>Queenstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SE1</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>E05000416</td>\n",
       "      <td>Bishop's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N9</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>Enfield</td>\n",
       "      <td>E05000201</td>\n",
       "      <td>Haselbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UB10</td>\n",
       "      <td>E09000017</td>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>E05000332</td>\n",
       "      <td>Hillingdon East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N7</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>Islington</td>\n",
       "      <td>E05000375</td>\n",
       "      <td>Holloway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postcode_district IncGeo_BoroughCode IncGeo_BoroughName IncGeo_WardCode  \\\n",
       "0              SW11          E09000032         Wandsworth       E05000620   \n",
       "1               SE1          E09000022            Lambeth       E05000416   \n",
       "2                N9          E09000010            Enfield       E05000201   \n",
       "3              UB10          E09000017         Hillingdon       E05000332   \n",
       "4                N7          E09000019          Islington       E05000375   \n",
       "\n",
       "   IncGeo_WardName  \n",
       "0       Queenstown  \n",
       "1         Bishop's  \n",
       "2        Haselbury  \n",
       "3  Hillingdon East  \n",
       "4         Holloway  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Easting_m</th>\n",
       "      <th>Northing_m</th>\n",
       "      <th>Easting_rounded</th>\n",
       "      <th>Northing_rounded</th>\n",
       "      <th>FRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>528652.0</td>\n",
       "      <td>176830.0</td>\n",
       "      <td>528650</td>\n",
       "      <td>176850</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530485.0</td>\n",
       "      <td>179007.0</td>\n",
       "      <td>530450</td>\n",
       "      <td>179050</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533773.0</td>\n",
       "      <td>194492.0</td>\n",
       "      <td>533750</td>\n",
       "      <td>194450</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>507738.0</td>\n",
       "      <td>182805.0</td>\n",
       "      <td>507750</td>\n",
       "      <td>182850</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>531058.0</td>\n",
       "      <td>185307.0</td>\n",
       "      <td>531050</td>\n",
       "      <td>185350</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Easting_m  Northing_m  Easting_rounded  Northing_rounded     FRS\n",
       "0   528652.0    176830.0           528650            176850  London\n",
       "1   530485.0    179007.0           530450            179050  London\n",
       "2   533773.0    194492.0           533750            194450  London\n",
       "3   507738.0    182805.0           507750            182850  London\n",
       "4   531058.0    185307.0           531050            185350  London"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IncidentStationGround</th>\n",
       "      <th>FirstPumpArriving_AttendanceTime</th>\n",
       "      <th>FirstPumpArriving_DeployedFromStation</th>\n",
       "      <th>SecondPumpArriving_AttendanceTime</th>\n",
       "      <th>SecondPumpArriving_DeployedFromStation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Battersea</td>\n",
       "      <td>319.0</td>\n",
       "      <td>Battersea</td>\n",
       "      <td>342.0</td>\n",
       "      <td>Clapham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edmonton</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>210.0</td>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holloway</td>\n",
       "      <td>233.0</td>\n",
       "      <td>Holloway</td>\n",
       "      <td>250.0</td>\n",
       "      <td>Holloway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  IncidentStationGround  FirstPumpArriving_AttendanceTime  \\\n",
       "0             Battersea                             319.0   \n",
       "1               Lambeth                               NaN   \n",
       "2              Edmonton                             308.0   \n",
       "3            Hillingdon                             210.0   \n",
       "4              Holloway                             233.0   \n",
       "\n",
       "  FirstPumpArriving_DeployedFromStation  SecondPumpArriving_AttendanceTime  \\\n",
       "0                             Battersea                              342.0   \n",
       "1                                   NaN                                NaN   \n",
       "2                              Edmonton                                NaN   \n",
       "3                            Hillingdon                                NaN   \n",
       "4                              Holloway                              250.0   \n",
       "\n",
       "  SecondPumpArriving_DeployedFromStation  \n",
       "0                                Clapham  \n",
       "1                                    NaN  \n",
       "2                                    NaN  \n",
       "3                                    NaN  \n",
       "4                               Holloway  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumStationsWithPumpsAttending</th>\n",
       "      <th>NumPumpsAttending</th>\n",
       "      <th>Postcode_full0</th>\n",
       "      <th>Postcode_full1</th>\n",
       "      <th>DatetimeOfCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SW11</td>\n",
       "      <td>4LB</td>\n",
       "      <td>2009-01-01 00:00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE1</td>\n",
       "      <td>7SG</td>\n",
       "      <td>2009-01-01 00:00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N9</td>\n",
       "      <td>9EL</td>\n",
       "      <td>2009-01-01 00:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UB10</td>\n",
       "      <td>0DG</td>\n",
       "      <td>2009-01-01 00:04:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N7</td>\n",
       "      <td>8HG</td>\n",
       "      <td>2009-01-01 00:05:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumStationsWithPumpsAttending  NumPumpsAttending Postcode_full0  \\\n",
       "0                            2.0                2.0           SW11   \n",
       "1                            NaN                NaN            SE1   \n",
       "2                            1.0                1.0             N9   \n",
       "3                            1.0                1.0           UB10   \n",
       "4                            1.0                2.0             N7   \n",
       "\n",
       "  Postcode_full1      DatetimeOfCall  \n",
       "0            4LB 2009-01-01 00:00:37  \n",
       "1            7SG 2009-01-01 00:00:46  \n",
       "2            9EL 2009-01-01 00:03:00  \n",
       "3            0DG 2009-01-01 00:04:27  \n",
       "4            8HG 2009-01-01 00:05:39  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour  month  weekday\n",
       "0     0      1        3\n",
       "1     0      1        3\n",
       "2     0      1        3\n",
       "3     0      1        3\n",
       "4     0      1        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#f1 = \"C:/Users/lloyd/data/LFB incident data 1 Jan 2009 to 31 Aug 2015/LFB incident data 1 Jan 2009 to 31 Dec 2011.csv\"\n",
    "f1 = \"/Users/david/data/LFB incident data 1 Jan 2009 to 31 Aug 2015/LFB incident data 1 Jan 2009 to 31 Dec 2011.csv\"\n",
    "\n",
    "df = pd.read_csv(f1, header=0, nrows = 100000)\n",
    "#df = pd.read_csv(f1, header=0, nrows = 150, infer_datetime_format=True)\n",
    "#df = df.convert_objects(convert_numeric=True)\n",
    "coltodatetime(df, \"DateOfCall\")\n",
    "coltodatetime(df, \"TimeOfCall\")\n",
    "splitcol(df, \"Postcode_full\", ' ')\n",
    "combinedatentime(df, \"DateOfCall\", \"TimeOfCall\", \"DatetimeOfCall\")\n",
    "df['hour'] = df[\"DatetimeOfCall\"].apply(lambda x : x.hour)\n",
    "df['month'] = df[\"DatetimeOfCall\"].apply(lambda x : x.month)\n",
    "df['weekday'] = df[\"DatetimeOfCall\"].apply(lambda x : x.weekday())\n",
    "print(\"Dataframe shape\")\n",
    "print(df.shape)\n",
    "print(\"Columns\")\n",
    "print(df.dtypes)\n",
    "print(\"Samples\")\n",
    "ut.dispdf(df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) figure out primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isunique(df, col):\n",
    "    return  len(df[col]) ==  len(set(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"IsUnique \", isunique(df, \"IncidentNumber\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) figure out what types of columns you have, numerical, categorical and nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitcoltypes(df):\n",
    "    numcols = []\n",
    "    datcols = []\n",
    "    catcols = []\n",
    "    for i in range(len(df.columns)):\n",
    "        if(df.dtypes[i] == \"object\"):\n",
    "            catcols.append(df.columns[i])\n",
    "        elif(df.dtypes[i] == \"datetime64[ns]\"):\n",
    "            datcols.append(df.columns[i])\n",
    "        else:\n",
    "            numcols.append(df.columns[i])\n",
    "    return numcols, datcols, catcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numcols, datcols, catcols = splitcoltypes(df)\n",
    "print(\"Numerical Columns\", len(numcols))\n",
    "print(numcols, \"\\n\")\n",
    "print(\"Datetime Columns\", len(datcols))\n",
    "print(datcols, \"\\n\")\n",
    "print(\"Categorical Columns\", len(catcols))\n",
    "print(catcols, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) deal with numerical\n",
    "- 4a) for each column, min, max, count, missing, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mad_based_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh\n",
    "\n",
    "def colstats(df, c):\n",
    "    vals = df[c]\n",
    "    count = len(vals)\n",
    "    min = np.min(vals)\n",
    "    max = np.max(vals)\n",
    "    per_25 = np.percentile(vals, 25)\n",
    "    mean = np.mean(vals)\n",
    "    per_75 = np.percentile(vals, 75)\n",
    "    std = np.std(vals)\n",
    "    #expected 3\n",
    "    kurt = sp.stats.kurtosis(vals)\n",
    "    skew = sp.stats.skew(vals)\n",
    "    nans = vals.isnull().sum()\n",
    "    per_nans = nans/count * 100\n",
    "    out_num = len(df[c][mad_based_outlier(df[c].values)])\n",
    "    out_per = out_num/count * 100\n",
    "\n",
    "    d = {\"count\": count, \"min\": min, \"max\": max, \"per_25\": per_25, \"mean\": mean,\n",
    "         \"per_75\": per_75, \"std\": std, \"kurt\": kurt, \"skew\": skew, \"nans\": nans, \n",
    "         \"nans_per\": per_nans, \"out_num\": out_num, \"out_per\": out_per\n",
    "        }\n",
    "    \n",
    "    st = pd.DataFrame.from_dict(d, orient='index')\n",
    "    st.rename(columns={0: c }, inplace=True)\n",
    "    st.sort_index(inplace=True)\n",
    "    return st\n",
    "\n",
    "def catstats(df, c):\n",
    "    vc = df[c].value_counts()\n",
    "    count = len(vc)\n",
    "\n",
    "    d = {\"catcount\": count, \n",
    "        }\n",
    "    \n",
    "    st = pd.DataFrame.from_dict(d, orient='index')\n",
    "    st.rename(columns={0: c }, inplace=True)\n",
    "    st.sort_index(inplace=True)\n",
    "    return st\n",
    "\n",
    "\n",
    "def removenans(df, c):\n",
    "    return df.dropna(subset=[c])\n",
    "\n",
    "def dataframestats(df):\n",
    "    stats = pd.DataFrame()\n",
    "    for c in df.columns:\n",
    "        if(not df[c].dtype == \"object\" and not df[c].dtype == \"datetime64[ns]\"):\n",
    "            st = colstats(df, c)\n",
    "            stats[c] = st[c]\n",
    "    return stats\n",
    "\n",
    "def dataframecatstats(df_local):\n",
    "    stats = pd.DataFrame()\n",
    "    for c in df_local.columns:\n",
    "        if(not df_local[c].dtype == 'float64' and not df_local[c].dtype == 'int64'):\n",
    "            print(df_local.shape)\n",
    "            st = catstats(df_local, c)\n",
    "            stats[c] = st[c]\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4b) shapes of distribution\n",
    "- 4c) fill in missing values/drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dist functions\n",
    "def showdist(df, c, threshold=3.5):\n",
    "    ut.figurefullwidth()\n",
    "    nans = df[c].isnull().sum()\n",
    "    vals = df[c].dropna().values\n",
    "    ut.subplottitle(1, \"Nans\", w=6)\n",
    "    plt.bar([1, 2], [len(df[c])-nans,nans], tick_label = [\"Ok\", \"NaN\"])\n",
    "    ut.subplottitle(2, \"Hist\", w=6)\n",
    "    plt.hist(vals, bins=20)\n",
    "    ut.subplottitle(3, \"Plot\", w=6)\n",
    "    plt.plot(vals, 'o')\n",
    "    ut.subplottitle(4, \"Box\", w=6)\n",
    "    sns.boxplot(vals)\n",
    "    outliers = mad_based_outlier(df[c].values)\n",
    "    outpoints = df[c][outliers]\n",
    "    ut.subplottitle(5, \"Distplot\", w=6)\n",
    "    sns.distplot(df[c], bins=20, hist=False)\n",
    "    ut.subplottitle(6, \"Outliers\", w=6)\n",
    "    plt.plot(outpoints, 'ro')\n",
    "    out_per = (len(outpoints)/df.shape[0])*100\n",
    "    nan_per = (nans/df.shape[0])*100\n",
    "    print(c,df.shape,\"Ouliers\", len(outpoints), \"{:1.2f}\".format(out_per),\"%\",\"Nans\",nans, \"{:1.2f}\".format(nan_per),\"%\",\"\\n\")\n",
    "    plt.show()\n",
    "    \n",
    "def examineonenumcol(df, c):\n",
    "    showdist(df, c)\n",
    "    #df2 = removeoutliers(df, c)\n",
    "    #chg = df2.shape[0] - df.shape[0]\n",
    "    #chg_per = chg / df.shape[0] * 100.0\n",
    "    #print(c, \"After\",df2.shape,chg, \"{:10.2f}\".format(chg_per) + \"%\", \"\\n\")\n",
    "    #showdist(df2, c)\n",
    "\n",
    "def removeoutliers(df, c, threshold=3.5):\n",
    "    outliers = mad_based_outlier(df[c].values)\n",
    "    outpoints = df[c][outliers]\n",
    "    return df.drop(outpoints.index)\n",
    "\n",
    "def removeoutliersfromcols(df, cols, threshold=3.5):\n",
    "    print(\"#===============================================\")\n",
    "    print(\"# Remove outliers from\", cols)\n",
    "    print(\"#===============================================\")\n",
    "\n",
    "    df2 = df.copy(deep=True)\n",
    "\n",
    "    for c in cols:\n",
    "        if(c in df2.columns):\n",
    "            df2 = removeoutliers(df2, c)\n",
    "    return df2\n",
    "\n",
    "def removecols(df, cols):\n",
    "    print(\"#===============================================\")\n",
    "    print(\"# Remove cols \", cols)\n",
    "    print(\"#===============================================\")\n",
    "    df2 = df.copy(deep=True)\n",
    "\n",
    "    for c in cols:\n",
    "        if(c in df2.columns):\n",
    "            df2 = df2.drop(c, axis=1)\n",
    "    return df2\n",
    "def removenansfromcols(df, cols):\n",
    "    print(\"#===============================================\")\n",
    "    print(\"# Remove nan from cols \", cols)\n",
    "    print(\"#===============================================\")\n",
    "    df2 = df.copy(deep=True)\n",
    "\n",
    "    for c in cols:\n",
    "        if(c in df2.columns):\n",
    "            val_list = df2[df2[c].apply(lambda x: np.isnan(x))]\n",
    "            print(len(val_list))\n",
    "            df2 =df2.drop(val_list.index)\n",
    "    return df2\n",
    "def makenormalfromexp(df, cols):\n",
    "    print(\"#===============================================\")\n",
    "    print(\"# make normal from exp\", cols)\n",
    "    print(\"#===============================================\")\n",
    "    df2 = df.copy(deep=True)\n",
    "\n",
    "    for c in cols:\n",
    "        if(c in df2.columns):\n",
    "            df2[c] = df2[c].apply(lambda x: 1/x)\n",
    "    return df2\n",
    "def makenormalfromlog(df, cols):\n",
    "    print(\"#===============================================\")\n",
    "    print(\"# make normal from lognormal\", cols)\n",
    "    print(\"#===============================================\")\n",
    "    df2 = df.copy(deep=True)\n",
    "\n",
    "    for c in cols:\n",
    "        if(c in df2.columns):\n",
    "            df2[c] = df2[c].apply(lambda x: np.log(x))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main area for adding / removing columns and transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dispcatdata(df, c):\n",
    "    vc = df[c].value_counts()\n",
    "    print(c, \" counttypes \",vc.shape[0],  \"\\n\")\n",
    "    if(vc.shape[0] > 100):\n",
    "        print(\"Data is large!!!!!!!!!!!! \" , vc.shape[0])\n",
    "    cumsum = np.cumsum(vc.values)\n",
    "    cumsum = cumsum/len(df[c])\n",
    "    if False:\n",
    "        ut.subplottitle(1, \"CumSum\")\n",
    "        plt.plot(cumsum)\n",
    "    #print(vc)\n",
    "    ut.figurefullwidth()\n",
    "    vc[:100].plot(kind='bar')\n",
    "    plt.show()\n",
    "    pro = 0;\n",
    "    for n in vc.values:\n",
    "        pro\n",
    "    \n",
    "def sigvals(df, c, threshold=0.8, num=0):\n",
    "    print(df.columns, c)\n",
    "    vc = df[c].value_counts()\n",
    "    names = vc.index.tolist()\n",
    "   \n",
    "    count = len(df[c])\n",
    "    cutoff = (int)(count * threshold)\n",
    "    acc = 0\n",
    "    num_acc = 0;\n",
    "    ret = []\n",
    "    others = []\n",
    "    for i in range(vc.shape[0]):\n",
    "        #print(names[i])\n",
    "        if acc < cutoff and num_acc < num -1:\n",
    "            ret.append(names[i])\n",
    "        else:\n",
    "            others.append(names[i])\n",
    "        acc += vc[i]\n",
    "        num_acc += 1\n",
    "    return ret, others\n",
    "\n",
    "\n",
    "def filteronsig(df, cols, threshold=0.8, num=0):\n",
    "    df2 = df.copy(deep=True)\n",
    "    for c in cols:\n",
    "        #print(c)\n",
    "        sig, others = sigvals(df2, c, threshold=threshold, num=num)\n",
    "        df2[c] = df2[c].apply(lambda x: x if x in sig else \"other\")\n",
    "    return df2\n",
    "\n",
    "def examineonecatcol(df_local, c, threshold):\n",
    "    df_temp = filteronsig(df_local, [c], threshold=threshold)\n",
    "    diff = df_local.shape[0] - df_temp.shape[0]\n",
    "    print(df_temp.shape, diff, \"{:1.2f}\".format(diff/df_local.shape[0]*100), \"% elements in bottom \", \"{:1.2f}\".format((1-threshold)*100), \"% of categories\")\n",
    "    dispcatdata(df_local, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "onehotencodings = {}\n",
    "def onehotencode(df, cols):\n",
    "    for c in cols:\n",
    "        if(c in df.columns):\n",
    "            pre_cols = df.columns\n",
    "            temp_col = df[c]\n",
    "            df = pd.get_dummies(df, columns=[c])\n",
    "            df[c] = temp_col\n",
    "            post_cols = df.columns\n",
    "            diff_cols = list(set(post_cols) - set(pre_cols))\n",
    "            onehotencodings[c] = diff_cols\n",
    "    return df\n",
    "   \n",
    "#dummyencodings = {}\n",
    "#def dummyencode(df2, col):\n",
    "#    if(df2[c].dtype == \"object\"):\n",
    "#        le = LabelEncoder()\n",
    "#        df2[c] = df2[c].apply(lambda x: 'NaN' if pd.isnull(x) else x)\n",
    "#        df2[c] = le.fit_transform(df2[c])\n",
    "#        encodings[c] = le\n",
    "#    return df\n",
    "\n",
    "def encodecols(df, catcols, dummy=False):\n",
    "    df2 = df.copy(deep=True)\n",
    "#    if(dummy):\n",
    "#        for c in catcols:\n",
    "#            if(c in df2.columns):\n",
    "#                df2 = dummyencode(df2, c)\n",
    "#    else:\n",
    "    df2 = onehotencode(df2, catcols)\n",
    "    return df2\n",
    "\n",
    "def printencodings(catcols):\n",
    "    tenc1 = pd.DataFrame()\n",
    "    for c in catcols:\n",
    "        if(c in onehotencodings):\n",
    "            classes = onehotencodings[c]\n",
    "            tenc = pd.DataFrame(classes, index = range(len(classes)))\n",
    "            tenc[c] = tenc[0]\n",
    "            del tenc[0]\n",
    "            ut.dispdf(tenc, num=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_temp = df\n",
    "print(\"Numerical columns\")\n",
    "print (numcols)\n",
    "print(\"Categorical columns\")\n",
    "print (catcols)\n",
    "outcols = ['IncidentNumber', 'Easting_m', 'Northing_m', 'Easting_rounded', 'Northing_rounded', 'FirstPumpArriving_AttendanceTime', 'SecondPumpArriving_AttendanceTime']\n",
    "remcols = ['Easting_m','Northing_m', 'SecondPumpArriving_AttendanceTime', 'SpecialServiceType','PropertyType','Postcode_full', \n",
    "           'IncGeo_BoroughCode', 'IncGeo_WardCode', 'Postcode_full0', 'Postcode_full1', 'FRS']\n",
    "nancols =  [\"FirstPumpArriving_AttendanceTime\",\"NumStationsWithPumpsAttending\",\"NumPumpsAttending\"]\n",
    "logcols = [\"FirstPumpArriving_AttendanceTime\", \"SecondPumpArriving_AttendanceTime\"]\n",
    "filtcols = [\"Postcode_district\", \"IncGeo_BoroughName\", \"IncGeo_WardName\", \"IncidentStationGround\", \"FirstPumpArriving_DeployedFromStation\", \"SecondPumpArriving_DeployedFromStation\"]\n",
    "\n",
    "if(False):\n",
    "    outcols = []\n",
    "    remcols = []\n",
    "    nancols =  []\n",
    "    logcols = []\n",
    "\n",
    "# After examination of dataset\n",
    "#===============================================\n",
    "# 1) Remove certain value, Nans \n",
    "#===============================================\n",
    "df_temp = removenansfromcols(df_temp,nancols)\n",
    "#===============================================\n",
    "# 2) make cols normal through ln\n",
    "#===============================================\n",
    "df_temp = makenormalfromlog(df_temp, logcols)\n",
    "#===============================================\n",
    "# 3) Remove outliers on cols\n",
    "#===============================================\n",
    "df_temp = removeoutliersfromcols(df_temp, outcols)\n",
    "#===============================================\n",
    "# 4) Remove cols that don't matter\n",
    "#===============================================\n",
    "df_temp = removecols(df_temp, remcols)\n",
    "#===============================================\n",
    "# 5) Filter cols with large cat number\n",
    "#===============================================\n",
    "df_temp = filteronsig(df_temp,filtcols, num=20)\n",
    " \n",
    "#===============================================\n",
    "# Examine the dataset\n",
    "#===============================================\n",
    "ignorecols = []\n",
    "#ignorecols = ['IncidentNumber', 'Easting_m','Northing_m','Easting_rounded','Northing_rounded']\n",
    "len(numcols)\n",
    "stats = dataframestats(df_temp)\n",
    "ut.dispdf(stats, 5, num=20)\n",
    "\n",
    "#Skip/Include examine of numericals\n",
    "if(True):\n",
    "    for c in numcols:\n",
    "        if(c not in ignorecols and c in df_temp.columns):\n",
    "            examineonenumcol(df_temp, c)\n",
    "        \n",
    "threshold = 0.8\n",
    "print(df_temp.shape)\n",
    "cstats = dataframecatstats(df_temp)\n",
    "ut.dispdf(cstats, 5, num=20)\n",
    "if(True):\n",
    "    for c in catcols:\n",
    "        if(c not in ignorecols and c in df_temp.columns):\n",
    "            examineonecatcol(df_temp, c, threshold)\n",
    "\n",
    "#===============================================\n",
    "# 6) ASSIGN it back to df - when you are happy with it!!!!!\n",
    "#===============================================\n",
    "if(True):\n",
    "    print(\"#===============================================\")\n",
    "    print(\"# ONE HOT ENCODING \")\n",
    "    print(\"#===============================================\")\n",
    "    #do the one hot encoding\n",
    "    print(catcols)\n",
    "    print(df_temp.shape)\n",
    "    df_temp = encodecols(df_temp, catcols)\n",
    "\n",
    "    df_orig = df\n",
    "    df = df_temp\n",
    "    df = df.reset_index(drop=True)\n",
    "    numcols, datcols, catcols = splitcoltypes(df)\n",
    "    print(\"#===============================================\")\n",
    "    print(\"# COMPLETE DATA CLEAN FOR df \")\n",
    "    print(\"#===============================================\")\n",
    "\n",
    "#print(\"#===============================================\")\n",
    "#print(\"# AFTER TRANSFORM\")\n",
    "#print(\"#===============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) deal with categorical\n",
    "- 5a) for each col count values\n",
    "- 5b) fill in missing values/drop them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) nlp -> look but dont touch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Finally remove the columns that dont' matter to get final dataset we can work on clealy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Nice clean data set we can do something to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7a) do a big old linear regression map and them iso map it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     38
    ],
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_matrix(cm, classesx, classesy,\n",
    "                          normalize=True,\n",
    "                          title='matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          axis=0):\n",
    "   \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marksx = np.arange(len(classesx))\n",
    "    plt.xticks(tick_marksx, classesx, rotation=90)\n",
    "    tick_marksy = np.arange(len(classesy))\n",
    "    plt.yticks(tick_marksy, classesy)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    ax.grid(False) \n",
    "    #for axi in (ax.xaxis, ax.yaxis):\n",
    "    #    for tic in axi.get_major_ticks():\n",
    "    #        tic.tick1On = tic.tick2On = True\n",
    "    #        tic.label1On = tic.label2On = False\n",
    "    orig = cm\n",
    "    if normalize:\n",
    "        if axis == 1:\n",
    "            cm = cm.astype('float') / cm.sum(axis=axis)[:, np.newaxis]\n",
    "        else:\n",
    "            cm = cm.astype('float') / cm.sum(axis=axis)\n",
    "    thresh = (cm.max() - cm.min()) * 0.5 + cm.min()\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        s = \"{:1.2f}\".format(cm[i,j])\n",
    "        #s = \"{:1.4f}\".format(cm[i,j]) + \"(\"+str(orig[i,j])+\")\"\n",
    "        plt.text(j, i, s, horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('Y label')\n",
    "    plt.xlabel('X label')\n",
    "\n",
    "def onelr(x1, y1):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x1, y1)\n",
    "    \n",
    "    return lr.score(x1, y1)\n",
    "\n",
    "def plotcorrel(df_temp, colsx, colsy):\n",
    "    num_coef = np.empty((len(colsx),len(colsy),))\n",
    "    num_coef[:] = np.NAN\n",
    "    x_labels = []\n",
    "    y_labels = []\n",
    "    for i in range(len(colsx)):\n",
    "        c_i = colsx[i]\n",
    "        if(c_i in df_temp.columns):\n",
    "            df_temp = df_temp.dropna(subset=[c_i])\n",
    "            y_labels.append(c_i + \"(\"+str(df_temp.shape[0])+\")\")\n",
    "            #print(c_i, df_temp.shape)\n",
    "            for j in range(len(colsy)):\n",
    "                c_j = colsy[j]\n",
    "                if len(x_labels)  < len(colsy):\n",
    "                     x_labels.append(c_j + \"(\"+str(df_temp.shape[0])+\")\")\n",
    "                if(c_j in df_temp.columns):\n",
    "                    df_temp = df_temp.dropna(subset=[c_j])\n",
    "                    vals_i = df_temp[c_i].values.reshape(-1,1)\n",
    "                    vals_j = df_temp[c_j].values.reshape(-1,1)\n",
    "                    if(np.isnan(vals_j).sum() == 0):\n",
    "                        #r = onelr(vals_i, vals_j)\n",
    "                        pcor = sp.stats.pearsonr(vals_i, vals_j)\n",
    "                        #print(pcor)\n",
    "                        num_coef[i, j] = pcor[0][0]\n",
    "    #print(num_coef)\n",
    "    ut.figurefullwidth()\n",
    "    plot_matrix(num_coef, x_labels, y_labels, normalize=False, title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "numcolsexOH = numcols\n",
    "for key in onehotencodings.keys():\n",
    "    numcolsexOH = list(set(numcolsexOH) - set(onehotencodings[key]))\n",
    "print(numcolsexOH)\n",
    "plotcorrel(df, numcolsexOH, numcolsexOH)\n",
    "plt.figure()\n",
    "#plt.plot(df[\"NumStationsWithPumpsAttending\"], df[\"NumPumpsAttending\"], 'o')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " \n",
    "def plot_catmatrix(cm, x_labels, y_labels,\n",
    "                          normalize=False,\n",
    "                          title='matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          y_title=\"\", x_title=\"\",\n",
    "                          axis=0):\n",
    "   \n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    #tick_marks = np.arange(len(x_labels))\n",
    "    plt.xticks(np.arange(len(x_labels)), x_labels, rotation=90)\n",
    "    plt.yticks(np.arange(len(y_labels)), y_labels)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    ax.grid(False) \n",
    "    #for axi in (ax.xaxis, ax.yaxis):\n",
    "    #    for tic in axi.get_major_ticks():\n",
    "    #        tic.tick1On = tic.tick2On = True\n",
    "    #        tic.label1On = tic.label2On = False\n",
    "    orig = cm\n",
    "    if normalize:\n",
    "        if axis == 1:\n",
    "            cm = cm.astype('float') / cm.sum(axis=axis)[:, np.newaxis]\n",
    "        else:\n",
    "            cm = cm.astype('float') / cm.sum(axis=axis)\n",
    "    thresh = (cm.max() - cm.min()) * 0.5 + cm.min()\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        v = cm[i,j]\n",
    "        if(np.isnan(v)):\n",
    "            s = '-'\n",
    "        else:\n",
    "            s = \"{:1.2f}\".format(v)\n",
    "        #s = \"{:1.4f}\".format(cm[i,j]) + \"(\"+str(orig[i,j])+\")\"\n",
    "        plt.text(j, i, s, horizontalalignment=\"center\",fontsize=8,\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(y_title)\n",
    "    plt.xlabel(x_title)\n",
    "    plt.show()\n",
    "\n",
    "def vc(df, c1, num=30):\n",
    "    vc1 = df[c1].value_counts()\n",
    "    n1 = vc1.index.tolist()\n",
    "    \n",
    "    if(len(n1) > num):\n",
    "        df_temp = filteronsig(df, [c1], num=num)\n",
    "        vc1 = df_temp[c1].value_counts()\n",
    "        n1 = vc1.index.tolist()\n",
    "    return vc1, n1\n",
    "\n",
    "\n",
    "            \n",
    "def plotcols(df, c1, c2):\n",
    "    print(c1, c2)\n",
    "    if(c1 in df.columns):\n",
    "        vc1, n1 = vc(df, c1)\n",
    "    else:\n",
    "        return\n",
    "    if(c2 in df.columns):\n",
    "        vc2, n2 = vc(df, c2)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    counts = np.empty((len(n1),len(n2),))\n",
    "    counts[:] = np.NAN\n",
    "    #print(vc2)\n",
    "    for i in range(len(n1)):\n",
    "        for j in range(len(n2)):\n",
    "            if(c1 in df.columns and c2 in df.columns):\n",
    "                c = len(df[(df[c1]==n1[i]) & (df[c2]==n2[j])])\n",
    "                #print(c)\n",
    "                counts[i,j] = c\n",
    "    #print(counts)\n",
    "    plot_catmatrix(np.transpose(counts), n1, n2, normalize=True, y_title=c2, x_title=c1)\n",
    "    #x = LabelEncoder().fit_transform(df[c1])\n",
    "    #y = LabelEncoder().fit_transform(df[c2])\n",
    "    #plt.plot(x, y, 'o')\n",
    "    #plt.show()\n",
    "len(catcols)\n",
    "#print(df.head())\n",
    "print(catcols)\n",
    "for c in catcols:\n",
    "    plotcols(df, catcols[0], c)\n",
    "#plotcols(df, catcols[0], catcols[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in catcols:\n",
    "    ohlist = onehotencodings[i]\n",
    "    print(i)\n",
    "    #print(ohlist)\n",
    "    #print(df_temp.shape)\n",
    "    ut.figurefullwidth()\n",
    "    plotcorrel(df_temp, ohlist, [\"FirstPumpArriving_AttendanceTime\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot categories vs 1 numberical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def boxplotcats(df, c2, catcols=catcols):\n",
    "    for c in catcols:\n",
    "        if(len(onehotencodings[c]) < 100):\n",
    "            #df_sub = inverseonehotencode(df, c,onehotencodings[c])\n",
    "            _ = sns.boxplot(x=c, y=c2, data=df)\n",
    "            _ = plt.xticks(rotation=90)\n",
    "            plt.show()\n",
    "\n",
    "def inverseonehotencode(df, col, cols):\n",
    "    df2 = df.copy(deep=True)\n",
    "    x = df2[cols].stack()\n",
    "    s = pd.Series(pd.Categorical(x[x!=0].index.get_level_values(1)))\n",
    "    df2[col] = s\n",
    "    df2 = df2.drop(cols, axis=1)\n",
    "    #print(s)\n",
    "    return df2\n",
    "\n",
    "#print(df.head())\n",
    "#print(inverseonehotencode(df, catcols[0],onehotencodings[catcols[0]]).head())\n",
    "#shall I do a clustering on the pump arrival times? \n",
    "#arrival times vs station?\n",
    "c2 = \"FirstPumpArriving_AttendanceTime\"\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "\n",
    "#t test means of data across category\n",
    "for c in catcols:\n",
    "    try:\n",
    "        print(c2, c)\n",
    "        p_vals = []\n",
    "        labels = []\n",
    "        sub_values = []\n",
    "        for c_sub1 in onehotencodings[c]:\n",
    "            sub_values.append(list(df[df[c_sub1] == 1][c2].values))\n",
    "        #print(sub_values)\n",
    "        #print(sub_values)\n",
    "        #ANOVA test 1 way\n",
    "        stat, pval = sp.stats.f_oneway(*sub_values)\n",
    "        print(\"ANOVA\", stat, pval)\n",
    "        #df_sub = inverseonehotencode(df, c, onehotencodings[c])\n",
    "        #print(df_sub[c].head())\n",
    "        #print(df_sub[c2].head())\n",
    "        mod = MultiComparison(df[c2], df[c])\n",
    "        tukey = mod.tukeyhsd()\n",
    "        print(mod.groupsunique)\n",
    "        #print()\n",
    "        #print(tukey.meandiffs)\n",
    "        print (tukey)\n",
    "        combs = list(itertools.combinations(mod.groupsunique, 2))\n",
    "        #print(len(combs))\n",
    "        ave_means = [];\n",
    "        for d in mod.groupsunique:\n",
    "            #print(d)\n",
    "            sum_means = 0;\n",
    "            count_means = 0;\n",
    "            for i in range(len(combs)):\n",
    "                #print(d, i)\n",
    "                a, b = combs[i]\n",
    "                if(a == d or b == d):\n",
    "                    sum_means += tukey.meandiffs[i]\n",
    "                    count_means += 1\n",
    "            ave_means.append(sum_means/count_means)\n",
    "        #print(ave_means, np.arange(len(mod.groupsunique)))\n",
    "        _ = plt.bar(np.arange(len(mod.groupsunique)), ave_means, align='center')\n",
    "        _ = plt.xticks(np.arange(len(mod.groupsunique)), mod.groupsunique)\n",
    "        _ = plt.xticks(rotation=90)\n",
    "        _ = plt.show()\n",
    "        boxplotcats(df, c2, catcols=[c])\n",
    "       \n",
    "    except Exception as e: \n",
    "        print (str(e))\n",
    "    #for c_sub1 in onehotencodings[c]:\n",
    "    #    sub1 = df[df[c_sub1] == 1][c2].values\n",
    "    #    sub1_not = df[df[c_sub1] == 0][c2].values\n",
    "    #    #Welch's t-test\n",
    "    #    _, p_val = sp.stats.ttest_ind(sub1, sub1_not, equal_var = False)\n",
    "    #    sig = p_val < 0.05\n",
    "    #    p_vals.append(p_val)\n",
    "    #    labels.append(c_sub1)\n",
    "    #    print(c_sub1, \"{:1.4f}\".format(p_val), \"Sig=\", sig, \"sub1mean=\", sub1.mean(), \"sub2mean=\", sub1_not.mean())\n",
    "    #plot_catmatrix(np.matrix([p_vals]), labels, [c2], normalize=False, y_title=c2, x_title=c)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 2 numerical - not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot2numerical(df_temp, c1, c2):\n",
    "    x = df_temp[c1]\n",
    "    y = df_temp[c2]\n",
    "    # fit with np.polyfit\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, y, '.')\n",
    "    plt.plot(x, m*x + b, '-')\n",
    "    plt.xlabel(c1)\n",
    "    plt.ylabel(c2)\n",
    "    plt.show()\n",
    "\n",
    "for c in numcolsexOH:\n",
    "    plot2numerical(df_temp, c2, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot categories vs 2 numerical - not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hour vs pump arrival time\n",
    "# for each category in BoroughName\n",
    "c2 = \"FirstPumpArriving_AttendanceTime\"\n",
    "c1 = \"weekday\"\n",
    "c3 = \"IncGeo_BoroughName\"\n",
    "print(onehotencodings)\n",
    "for c in onehotencodings[c3]:\n",
    "    #print(c)\n",
    "    df_temp2 = df_temp[df_temp[c].apply(lambda x: x == 1)]\n",
    "    plot2numerical(df_temp2, c1, c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do a random forest to see what affects dependent var "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse(pred, act):\n",
    "    diff = np.mean(np.power(pred-act, 2))\n",
    "    return diff\n",
    "\n",
    "def oneRF(df, c_xs, c_y):\n",
    "    #print(c_xs, c_y)\n",
    "    x1 = df[c_xs].values\n",
    "    y1 = df[c_y].values.reshape(-1, 1)\n",
    "    #print(x1)\n",
    "    #print(y1)\n",
    "    #normalise the data\n",
    "    scaler = StandardScaler()\n",
    "    x1 = scaler.fit_transform(x1)\n",
    "    #x2 = scaler.transform(x2)\n",
    "    sv = RandomForestRegressor()\n",
    "    \n",
    "    estimators = []\n",
    "    estimators.append((\"RF\", sv))\n",
    "    model = Pipeline(estimators)\n",
    "    param_rf = {\"RF__max_depth\": [3],\n",
    "              #\"RF__max_features\": [1, 3],\n",
    "              \"RF__min_samples_split\": [ 3],\n",
    "              \"RF__min_samples_leaf\": [3],\n",
    "              \"RF__bootstrap\": [True, False],\n",
    "               }\n",
    "    \n",
    "    cv_splits = 2\n",
    "   \n",
    "   \n",
    "    svm = GridSearchCV(model, cv=cv_splits, param_grid=param_rf)\n",
    "    svm.fit(x1, y1)\n",
    "    y1_pred = svm.predict(x1)\n",
    "    s_in = mse(y1_pred, np.squeeze(y1))\n",
    "    #s_out = svm.score(x2, y2)\n",
    "    return s_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2 = \"FirstPumpArriving_AttendanceTime\"\n",
    "#finding the best predictor of c2\n",
    "\n",
    "iteration = 0\n",
    "colsleft = numcols\n",
    "colsincluded = []\n",
    "total_mse = []\n",
    "iteration_list = [];\n",
    "#picker doesn't quite seem to be doing as good a job as all columns\n",
    "while(iteration < 160):\n",
    "    res_list = []\n",
    "    if(len(colsleft) == 0):\n",
    "        break\n",
    "    print(\"iteration\", iteration)\n",
    "    print(\"colsleft\", len(colsleft))\n",
    "    acc = 0;\n",
    "    for c in colsleft:\n",
    "        if(not c == c2):\n",
    "            temp_cols = colsincluded + [c]\n",
    "            #print(temp_cols)\n",
    "            s_in = oneRF(df, temp_cols, c2)\n",
    "            res_list.append({\"col\": c, \"s_in\": s_in})\n",
    "            acc +=1\n",
    "            print(\"(\"+str(acc)+\")\", s_in, end=\"\")\n",
    "\n",
    "    res = pd.DataFrame(res_list)\n",
    "    res = res.sort_values([\"s_in\"])\n",
    "    #res = res.reindex(range(0, len(res)))\n",
    "    print(res.head())\n",
    "    #---------------------------------------\n",
    "    # select best k columns\n",
    "    #---------------------------------------\n",
    "    for i in range(20):\n",
    "        if(len(res) > 0):\n",
    "            bestcol = res[\"col\"].iloc[0]\n",
    "            print(\"BEST COLUMN \", bestcol)\n",
    "            res = res.drop(res.index[0])\n",
    "            colsincluded.append(bestcol)\n",
    "    \n",
    "    s_cur = oneRF(df, colsincluded, c2)\n",
    "    iteration_list.append(iteration)\n",
    "    total_mse.append(s_cur)\n",
    "    \n",
    "    colsleft = res[\"col\"].values\n",
    "    iteration+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Fit benchmark of all columns\")\n",
    "#calc with all columns in it\n",
    "numcolsexc2 = list(set(numcols)- set([c2]))\n",
    "s_in_max = oneRF(df, numcolsexc2, c2)\n",
    "horiz_line_data = [iteration_list[0], iteration_list[-1]]\n",
    "plt.plot( horiz_line_data,[s_in_max, s_in_max], 'r') \n",
    "\n",
    "plt.plot(iteration_list, total_mse)\n",
    "print(len(numcols), s_in_max)\n",
    "print(len(colsincluded), total_mse[-1])\n",
    "plt.show()\n",
    "\n",
    "#might not use this function\n",
    "def dorandtes():    \n",
    "    randtests = 10\n",
    "    randdf = pd.DataFrame(np.random.randint(0,100,size=(df.shape[0], randtests)))\n",
    "    randdf[c2] = df[c2]\n",
    "    print(randdf.head())\n",
    "    randlist = []\n",
    "    for c in randdf.columns:\n",
    "        s_in = oneRF(randdf, [c], c2)\n",
    "        randlist.append(s_in)\n",
    "\n",
    "    mean = np.mean(randlist)\n",
    "    std = np.std(randlist)\n",
    "    up_limit = mean + 2* std\n",
    "    low_limit = mean - 2* std\n",
    "    res_list.append({\"col\": \"up_rand\", \"s_in\": up_limit})\n",
    "    res_list.append({\"col\": \"mean_rand\", \"s_in\": mean})\n",
    "    res_list.append({\"col\": \"low_rand\", \"s_in\": low_limit})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "-------\n",
    "1. General thoughts on the dataset\n",
    "2. Specific question\n",
    "* Is BLM charging the right amount vs man hours?\n",
    "3. What data do we have to answer that question?\n",
    "4. What data we use? high correlation\n",
    "5. LR of man hours vs charge\n",
    "6 Look at LR with groupings of different case types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(numcols), s_in_max)\n",
    "print(len(colsincluded), total_mse[-1])\n",
    "s_in_max = oneRF(df, numcols, c2)\n",
    "horiz_line_data = [iteration_list[0], iteration_list[-1]]\n",
    "plt.plot( horiz_line_data,[s_in_max, s_in_max], 'r') \n",
    "\n",
    "plt.plot(iteration_list, total_mse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
