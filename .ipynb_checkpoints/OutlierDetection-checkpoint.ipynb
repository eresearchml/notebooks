{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Example settings\n",
    "n_samples = 200\n",
    "outliers_fraction = 0.25\n",
    "clusters_separation = [0, 1, 2]\n",
    "\n",
    "# define two outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    \"One-Class SVM\": svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05,\n",
    "                                     kernel=\"rbf\", gamma=0.1),\n",
    "    \"Robust covariance\": EllipticEnvelope(contamination=outliers_fraction),\n",
    "    \"Isolation Forest\": IsolationForest(max_samples=n_samples,\n",
    "                                        contamination=outliers_fraction,\n",
    "                                        random_state=rng)}\n",
    "\n",
    "# Compare given classifiers under given settings\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 500), np.linspace(-7, 7, 500))\n",
    "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "ground_truth = np.ones(n_samples, dtype=int)\n",
    "ground_truth[-n_outliers:] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the problem with varying cluster separation\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    X1 = 0.3 * np.random.randn(n_inliers // 2, 2) - offset\n",
    "    X2 = 0.3 * np.random.randn(n_inliers // 2, 2) + offset\n",
    "    X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "\n",
    "    # Fit the model\n",
    "    plt.figure(figsize=(10.8, 3.6))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        # fit the data and tag outliers\n",
    "        clf.fit(X)\n",
    "        scores_pred = clf.decision_function(X)\n",
    "        threshold = stats.scoreatpercentile(scores_pred,\n",
    "                                            100 * outliers_fraction)\n",
    "        y_pred = clf.predict(X)\n",
    "        n_errors = (y_pred != ground_truth).sum()\n",
    "        # plot the levels lines and the points\n",
    "        Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        subplot = plt.subplot(1, 3, i + 1)\n",
    "        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
    "                         cmap=plt.cm.Blues_r)\n",
    "        a = subplot.contour(xx, yy, Z, levels=[threshold],\n",
    "                            linewidths=2, colors='red')\n",
    "        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
    "                         colors='orange')\n",
    "        b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white')\n",
    "        c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black')\n",
    "        subplot.axis('tight')\n",
    "        subplot.legend(\n",
    "            [a.collections[0], b, c],\n",
    "            ['learned decision function', 'true inliers', 'true outliers'],\n",
    "            prop=matplotlib.font_manager.FontProperties(size=11),\n",
    "            loc='lower right')\n",
    "        subplot.set_title(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
    "        subplot.set_xlim((-7, 7))\n",
    "        subplot.set_ylim((-7, 7))\n",
    "    plt.subplots_adjust(0.04, 0.1, 0.96, 0.92, 0.1, 0.26)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
