{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multilayer Perceptron to Predict International Airline Passengers (t+1, given t)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "from IPython.core.debugger import Tracer\n",
    "from sklearn import datasets, linear_model\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import operator\n",
    "import itertools\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#Tracer()()\n",
    "def prep (a):\n",
    "    return a.reshape(a.shape[0], 1)\n",
    "def unprep (a):\n",
    "    return np.squeeze(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from IPython.core.display import HTML\n",
    "#HTML(\"<style> div.code_cell{width: 75%;float: left;}\"\n",
    "#    +\"div.text_cell{width: 25%;float: right;}\"\n",
    "#    +\"div.text_cell div.prompt {display: none;}</style>\")\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pandas.read_csv('/Users/david/notebooks/data/futs1.csv', usecols=[0:2], engine='python', skipfooter=3)\n",
    "df = pd.read_csv('/Users/david/notebooks/data/futs1.csv', header=3)\n",
    "df = df.drop(df.columns[3:], axis=1) \n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Date        OPEN  VOLUME\n",
      "0 2016-09-01 09:00:00  130.671875     871\n",
      "1 2016-09-01 09:01:00  130.656250      14\n",
      "2 2016-09-01 09:02:00  130.656250     103\n",
      "3 2016-09-01 09:03:00  130.656250     395\n",
      "4 2016-09-01 09:04:00  130.656250     186\n",
      "                  Date        OPEN  VOLUME       CHG  PREVVOLUME  NXTUP\n",
      "1  2016-09-01 09:01:00  130.656250      14 -0.015625       871.0     -1\n",
      "2  2016-09-01 09:02:00  130.656250     103  0.000000        14.0     -1\n",
      "3  2016-09-01 09:03:00  130.656250     395  0.000000       103.0     -1\n",
      "4  2016-09-01 09:04:00  130.656250     186  0.000000       395.0     -1\n",
      "5  2016-09-01 09:05:00  130.656250    3108  0.000000       186.0     -1\n",
      "6  2016-09-01 09:06:00  130.656250     453  0.000000      3108.0     -1\n",
      "7  2016-09-01 09:07:00  130.656250     198  0.000000       453.0     -1\n",
      "8  2016-09-01 09:08:00  130.671875     249  0.015625       198.0      1\n",
      "9  2016-09-01 09:09:00  130.656250     425 -0.015625       249.0     -1\n",
      "10 2016-09-01 09:10:00  130.671875    1059  0.015625       425.0      1\n",
      "11 2016-09-01 09:11:00  130.656250     109 -0.015625      1059.0     -1\n",
      "12 2016-09-01 09:12:00  130.656250     162  0.000000       109.0     -1\n",
      "13 2016-09-01 09:13:00  130.671875     117  0.015625       162.0      1\n",
      "14 2016-09-01 09:14:00  130.656250     186 -0.015625       117.0     -1\n",
      "15 2016-09-01 09:15:00  130.671875      12  0.015625       186.0      1\n",
      "16 2016-09-01 09:16:00  130.656250      52 -0.015625        12.0     -1\n",
      "17 2016-09-01 09:17:00  130.671875      65  0.015625        52.0      1\n",
      "18 2016-09-01 09:18:00  130.671875    1875  0.000000        65.0     -1\n",
      "19 2016-09-01 09:19:00  130.671875     310  0.000000      1875.0     -1\n",
      "20 2016-09-01 09:20:00  130.687500     565  0.015625       310.0      1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>OPEN</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>CHG</th>\n",
       "      <th>PREVVOLUME</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NXTUP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>44486</td>\n",
       "      <td>44486</td>\n",
       "      <td>44486</td>\n",
       "      <td>44486</td>\n",
       "      <td>44486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12633</td>\n",
       "      <td>12633</td>\n",
       "      <td>12633</td>\n",
       "      <td>12633</td>\n",
       "      <td>12633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   OPEN  VOLUME    CHG  PREVVOLUME\n",
       "NXTUP                                         \n",
       "-1     44486  44486   44486  44486       44486\n",
       " 1     12633  12633   12633  12633       12633"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2[\"CHG\"] = df2[\"OPEN\"] - df2[\"OPEN\"].shift(1)\n",
    "df2[\"PREVVOLUME\"] = df2[\"VOLUME\"].shift(1)\n",
    "df2[\"NXTUP\"] = df2[\"CHG\"].apply(lambda x: int(1) if x > 0 else int(-1))\n",
    "df2 = df2.dropna()\n",
    "#df.loc[3:]\n",
    "#df.head()\n",
    "print(df.head())\n",
    "print(df2.head(20))\n",
    "#print(df2[\"NXTUP\"].describe())\n",
    "df2.groupby('NXTUP').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_e (x, y):\n",
    "    #Predictor comparison\n",
    "    res = x - y\n",
    "    res_e = np.sqrt(np.mean(res**2))\n",
    "    #print(res_e)\n",
    "    return res_e, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_score (x, y):\n",
    "    #Predictor comparison\n",
    "    res = x - y\n",
    "    res_e = np.sqrt(np.mean(res**2))\n",
    "    #print(res_e)\n",
    "    return res_e, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dumb_p (x1, y1):\n",
    "    res_e_simple, res_simple = calc_e(unprep(x1), unprep(y1))\n",
    "    return res_e_simple, res_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prob_move(p, start, end):\n",
    "    d = dict()\n",
    "    x1 = p[start:end,:1]\n",
    "    #print(x1)\n",
    "    for i in range(0, end-start):\n",
    "        #just the simple ts\n",
    "        c1 = x1[i-1] - x1[i]\n",
    "        if c1[0] not in d:\n",
    "            d[c1[0]] = 0\n",
    "        d[c1[0]] +=1\n",
    "    s = sum(d.values())\n",
    "    for k in d.keys():\n",
    "        d[k] = d[k]/s\n",
    "    #print(d)\n",
    "    #print(sum(d.values()))\n",
    "    r = sumproduct(d.keys(), d.values())\n",
    "    return r, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sumproduct(A, B):\n",
    "    return sum([i*j for i,j in zip(A,B)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maxkey(stats):\n",
    "    return max(stats, key=lambda key: stats[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          axis=0):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    orig = cm\n",
    "    if normalize:\n",
    "        if axis == 1:\n",
    "            cm = cm.astype('float') / cm.sum(axis=axis)[:, np.newaxis]\n",
    "        else:\n",
    "            cm = cm.astype('float') / cm.sum(axis=axis)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        #thresh = cm[i].max() / 2.\n",
    "        thresh = orig.sum(axis=axis)[i]*0.5\n",
    "        thresh2 = orig.sum()\n",
    "        print(i, j, thresh, thresh2, orig[i,j])\n",
    "        #col = \"black\"\n",
    "        s = \"{:1.4f}\".format(cm[i,j]) + \"(\"+str(orig[i,j])+\")\"\n",
    "        plt.text(j, i, s,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if orig[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sub_p_svm (x1, y1, x2, y2, do_plot=False):\n",
    "    #normalise the data\n",
    "    scaler = StandardScaler()\n",
    "    x1 = scaler.fit_transform(x1)\n",
    "    x2 = scaler.transform(x2)\n",
    "    #svm = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=4,\n",
    "    #                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "    #                    \"gamma\": np.logspace(-2, 2, 5)})\n",
    "    svm = GridSearchCV(SVC(kernel='rbf', gamma=0.1), cv=4,\n",
    "                       param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                        \"gamma\": np.logspace(-2, 2, 5)})\n",
    "    #print(x1)\n",
    "    #print(y1)\n",
    "    #print(x2)\n",
    "    #print(y2)\n",
    "    #Tracer()()\n",
    "    #print(\"mean\", x1.mean(axis=0), \"std\", x1.std(axis=0))\n",
    "\n",
    "    svm.fit(x1, y1)\n",
    "    y1_svr = svm.predict(x1)\n",
    "    y2_svr = svm.predict(x2)\n",
    "    svm_num = svm.best_estimator_.n_support_\n",
    "    res_e_in = svm.score(x1, y1)\n",
    "    res_e = svm.score(x2, y2)\n",
    "    y3 = np.full(len(y2), -1)\n",
    "    #always do nothing\n",
    "    res_e_simple = accuracy_score(y2, y3)\n",
    "    cm = confusion_matrix(y2, y2_svr, labels=[-1, 1])\n",
    "    cm_simple = confusion_matrix(y3, y2_svr, labels=[-1, 1])\n",
    "   \n",
    "    #print(mycm(y2, y2_svr))\n",
    "    #print(cm)\n",
    "    \n",
    "    if do_plot:\n",
    "        plt.figure()\n",
    "        plt.clf()\n",
    "        d = {\"-1\": \"blue\", \"1\":\"yellow\"}\n",
    "        c1 = list(map(lambda x : \"yellow\" if x == -1 else \"green\", a1))\n",
    "        patch1 = mpatches.Patch(color='yellow', label='-1 CNG<=0')\n",
    "        patch2 = mpatches.Patch(color='green', label='+1 CNG>0')\n",
    "        plt.legend(handles=[patch1, patch2])\n",
    "        plt.scatter(x1[:, 0], x1[:, 1], c=c1, zorder=10, cmap=plt.cm.Paired)\n",
    "        #plt.scatter(x2[:, 0], x2[:, 1], s=80, facecolors='none', zorder=10)\n",
    "        plt.scatter(x2[:, 0], x2[:, 1], s=280, c=\"k\", marker='+', zorder=10, lw=2)\n",
    "\n",
    "        #plt.axis('tight')\n",
    "        x_min = x1[:, 0].min()\n",
    "        x_max = x1[:, 0].max()\n",
    "        y_min = x1[:, 1].min()\n",
    "        y_max = x1[:, 1].max()\n",
    "\n",
    "        XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "        Z = svm.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(XX.shape)\n",
    "        plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "        plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "        plt.title(\"svm\")#plt.plot(unprep(x1), y1_svr, 'o')\n",
    "        plt.show()\n",
    "        #plt.figure()\n",
    "        #plt.plot(unprep(x2), y2_svr, 'o')\n",
    "        #plt.figure()\n",
    "        #plt.plot(res)\n",
    "        #plt.figure()\n",
    "        #plt.plot(unprep(x1), label =\"X\")\n",
    "        #plt.plot(y1_svr, label =\"y_in\")\n",
    "        #plt.legend(loc=\"best\")\n",
    "        #plt.figure()\n",
    "        #plt.plot(unprep(x2), label =\"X\")\n",
    "        #plt.plot(y2_svr, label =\"y_out\")\n",
    "        #plt.legend(loc=\"best\")\n",
    "    return res_e_in, res_e, res_e_simple, cm, cm_simple, svm_num.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mycm(actual, predict):\n",
    "    return pd.crosstab(actual, predict, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 10) (5000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 130.65625 ,  130.671875,  130.65625 , ...,  130.65625 ,\n",
       "         130.65625 ,  130.65625 ],\n",
       "       [ 130.65625 ,  130.65625 ,  130.671875, ...,  130.65625 ,\n",
       "         130.65625 ,  130.65625 ],\n",
       "       [ 130.671875,  130.65625 ,  130.65625 , ...,  130.65625 ,\n",
       "         130.65625 ,  130.65625 ],\n",
       "       ..., \n",
       "       [ 131.421875,  131.421875,  131.421875, ...,  131.40625 ,\n",
       "         131.40625 ,  131.421875],\n",
       "       [ 131.421875,  131.421875,  131.421875, ...,  131.421875,\n",
       "         131.40625 ,  131.40625 ],\n",
       "       [ 131.421875,  131.421875,  131.421875, ...,  131.40625 ,\n",
       "         131.421875,  131.40625 ]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------\n",
    "# prep the daa\n",
    "#--------------------------\n",
    "\n",
    "size = 5000\n",
    "#w1 = prep(df2[\"OPEN\"].shift(0).values[0:size])\n",
    "fnum = 10\n",
    "X = np.transpose([df2[label].shift(i).values[fnum:size+fnum]  for i in range(fnum) for label in [\"OPEN\"]])\n",
    "y = df2[\"NXTUP\"].shift(-1).values[fnum:size+fnum]\n",
    "print(np.shape(X), np.shape(y))\n",
    "X\n",
    "#print(X[4])\n",
    "#print(X)\n",
    "#print(y)\n",
    "#print(np.shape(np.transpose(X)))\n",
    "#y = prep(df2[\"OPEN\"].shift(-1).values[0:size])\n",
    "#print(np.shape(d))\n",
    "#for i in range(np.shape(d)[0]):\n",
    "#    plt.plot(d[i])\n",
    "#    print(d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.array([1, 1, 2, 2])\n",
    "#df2[\"NXTUP\"].shift(-1).values[fnum:size+fnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, "
     ]
    }
   ],
   "source": [
    "#----------------------------------------\n",
    "# Main Work\n",
    "#----------------------------------------\n",
    "step = 10\n",
    "train_len = 100\n",
    "test_len = step\n",
    "\n",
    "#last val as pred for next val\n",
    "#s1, res_s = dumb_p(X[:train_len, 0], y[:train_len])\n",
    "#s2, res_s = dumb_p(X[train_len:, 0], y[train_len:])\n",
    "#Tracer()()\n",
    "#f = 1\n",
    "start_train = 0\n",
    "end_train = start_train + train_len\n",
    "e_out_ar = []\n",
    "e_in_ar =[]\n",
    "e_simple_ar = []\n",
    "\n",
    "b1_ar = []\n",
    "cm_ar = []\n",
    "cm_simple_ar = []\n",
    "svm_num_ar = []\n",
    "it = 0\n",
    "max = 200\n",
    "while end_train < len(X):\n",
    "    if it >= max:\n",
    "        break\n",
    "    end_train = np.min([start_train + train_len, len(X)])\n",
    "    end_test = end_train + test_len\n",
    "    l1 = len(X) - end_train\n",
    "    if l1 ==0:\n",
    "        break\n",
    "    #do stuff\n",
    "    for f in [2]:\n",
    "        #print(X[start_train:end_train,:f].shape)\n",
    "    \n",
    "        e_in, e_out, e_simple, cm, cm_simple, svm_num = sub_p_svm(X[start_train:end_train,:f], y[start_train:end_train], \n",
    "                            X[end_train:end_test,:f], y[end_train:end_test], do_plot=False)\n",
    "        e_in_ar.append(e_in)\n",
    "        e_out_ar.append(e_out)\n",
    "        e_simple_ar.append(e_simple)\n",
    "        cm_ar.append(cm)\n",
    "        cm_simple_ar.append(cm_simple)\n",
    "        svm_num_ar.append(svm_num)\n",
    "    #s3, res_s = dumb_p(X[start_train:end_train, 0], y[start_train:end_train])\n",
    "    #s4, res_s = dumb_p(X[end_train:end_test, 0], y[end_train:end_test])\n",
    "    #s3_ar.append(s3)\n",
    "    #s4_ar.append(s4)\n",
    "    #s3_ar.append(0.5)\n",
    "    #s4_ar.append(0.5)\n",
    "    \n",
    "    #b_dict = prob_move(X, start_train, end_train)\n",
    "    print (end_train, end=\", \")\n",
    "    #print(e_in, e_out)\n",
    "    start_train += step\n",
    "    it += 1\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(e_out_ar, label='eout_'+str(f))\n",
    "plt.plot(e_simple_ar, label=\"simp_out\", color = 'g')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "#print(cm_ar)\n",
    "#print([cm_ar[i][0,0] for i in range(len(cm_ar))])\n",
    "up_right = np.array([cm_ar[i][1,1] for i in range(len(cm_ar))])\n",
    "up_wrong = np.array([cm_ar[i][0,1] for i in range(len(cm_ar))])\n",
    "#up_per = np.nan_to_num(up_right / (up_right + up_wrong))\n",
    "up_per = up_right / (up_right + up_wrong)\n",
    "\n",
    "tot = [np.sum([cm_ar[i][y,x] for i in range(len(cm_ar))]) for y in range(2) for x in range(2)]\n",
    "tot1 = np.array(tot).reshape(2, 2)\n",
    "tot_simple = [np.sum([cm_simple_ar[i][y,x] for i in range(len(cm_simple_ar))]) for x in range(2) for y in range(2)]\n",
    "tot1_simple = np.array(tot_simple).reshape(2, 2)\n",
    "labels = ['CHG<=0','CHG>0']\n",
    "#print(tot)\n",
    "plot_confusion_matrix(tot1, labels, normalize=True, title =\"CM SVM\")\n",
    "plot_confusion_matrix(tot1_simple, labels, normalize=True, title =\"CM Simple\")\n",
    "plt.figure()\n",
    "plt.plot(np.array(svm_num_ar)/train_len)\n",
    "plt.plot(up_per, 'o')\n",
    "#tot[0,1] = [cm_ar[i][0,1] for i in range(len(cm_ar))]\n",
    "#tot[1,0] = [cm_ar[i][1,0] for i in range(len(cm_ar))]\n",
    "#tot[1,1] = [cm_ar[i][1,1] for i in range(len(cm_ar))]\n",
    "#plt.figure()\n",
    "#plt.plot(e_in_ar, label=\"ein\")\n",
    "#plt.plot(s3_ar, label=\"simp_in\", color = 'g')\n",
    "#plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 37\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[ 5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0\n",
      "  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 10  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[[5 5]\n",
      " [0 0]]\n",
      "[[7 0]\n",
      " [3 0]]\n",
      "[[8 0]\n",
      " [2 0]]\n",
      "[[9 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(up_right.sum(), up_wrong.sum())\n",
    "print(np.array([cm_ar[i][1,1] for i in range(len(cm_ar))]))\n",
    "print(np.array([cm_ar[i][0,1] for i in range(len(cm_ar))]))\n",
    "print(cm_ar[0])\n",
    "print(cm_ar[1])\n",
    "print(cm_ar[2])\n",
    "print(cm_ar[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yellow', 'green', 'yellow']\n",
      "<matplotlib.colors.LinearSegmentedColormap object at 0x10befff98>\n"
     ]
    }
   ],
   "source": [
    "a1 = [-1, 1, -1]\n",
    "a2 = map(lambda x : \"yellow\" if x == -1 else \"green\", a1)\n",
    "print(list(a2))\n",
    "print(plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "a = 0.99923\n",
    "b = 234\n",
    "s = \"{:1.4f}\".format(a) + \"(\"+str(b)+\")\"\n",
    "s\n",
    "y3 = np.full(4, -1)\n",
    "print(y3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
